# Домашнее задание к занятию «Обновление приложений»

### Цель задания

Выбрать и настроить стратегию обновления приложения.

### Чеклист готовности к домашнему заданию

1. Кластер K8s.

### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Документация Updating a Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment).
2. [Статья про стратегии обновлений](https://habr.com/ru/companies/flant/articles/471620/).

-----

### Задание 1. Выбрать стратегию обновления приложения и описать ваш выбор

1. Имеется приложение, состоящее из нескольких реплик, которое требуется обновить.
2. Ресурсы, выделенные для приложения, ограничены, и нет возможности их увеличить.
3. Запас по ресурсам в менее загруженный момент времени составляет 20%.
4. Обновление мажорное, новые версии приложения не умеют работать со старыми.
5. Вам нужно объяснить свой выбор стратегии обновления приложения.

### Решение

~~~
Можно использовать Canary Strategy. Указав параметры maxSurge maxUnavailable, чтобы избежать нехватки ресурсов. 
Это позволит нам протестировать новую версию программы на реальной пользовательской базе
(группа может выделяться по определенному признаку) без обязательства полного развертывания. 
После тестирования и собирания метрик,  пользователей можно постепенно переводить  поды к новой версии приложения.

Либо, если приложение уже протестировано ранее, то  будем использовать стратегию обновления Rolling Update,
 указанием параметров maxSurge maxUnavailable для избежания ситуации с нехваткой ресурсов.
 Проводить обновление следует в менее загруженный момент времени сервиса.
При данной стратегии(Rolling Update) k8s постепенно заменит все поды без ущерба производительности.
 И если что-то пойдет не так, можно будет быстро откатится к предыдущему состоянию.

Этот вариант и выберем.

~~~

### Задание 2. Обновить приложение

1. Создать deployment приложения с контейнерами nginx и multitool. Версию nginx взять 1.19. Количество реплик — 5.



Сделал:

[depoyments.yaml](https://github.com/zatulik2606/Microservices/blob/main/k8supdsoft/deployments.yaml)

[svc.yaml](https://github.com/zatulik2606/Microservices/blob/main/k8supdsoft/svc.yaml)

~~~
admin@ubuntu-hw:~/k8supdsoft$ kubectl get po
NAME                                  READY   STATUS    RESTARTS   AGE
netology-deployment-666dcf88d-qd7g7   2/2     Running   0          31s
netology-deployment-666dcf88d-9r456   2/2     Running   0          31s
netology-deployment-666dcf88d-x2fjk   2/2     Running   0          31s
netology-deployment-666dcf88d-rtw8w   2/2     Running   0          31s
netology-deployment-666dcf88d-rmksj   2/2     Running   0          31s
admin@ubuntu-hw:~/k8supdsoft$ kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
kubernetes   ClusterIP   10.152.183.1     <none>        443/TCP             21m
mysvc        ClusterIP   10.152.183.227   <none>        9001/TCP,9002/TCP   12s
admin@ubuntu-hw:~/k8supdsoft$ 


~~~

~~~

admin@ubuntu-hw:~/k8supdsoft$ kubectl get pod netology-deployment-666dcf88d-rmksj -o yaml
apiVersion: v1
kind: Pod
metadata:
  annotations:
    cni.projectcalico.org/containerID: 100c46fb3c280b30ee783f40558e641b1df69941abb43bf5cece21bb9b70a486
    cni.projectcalico.org/podIP: 10.1.169.85/32
    cni.projectcalico.org/podIPs: 10.1.169.85/32
  creationTimestamp: "2024-02-15T09:36:29Z"
  generateName: netology-deployment-666dcf88d-
  labels:
    app: main
    pod-template-hash: 666dcf88d
  name: netology-deployment-666dcf88d-rmksj
  namespace: default
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: ReplicaSet
    name: netology-deployment-666dcf88d
    uid: fddecaee-9aa6-4267-b4a2-41e9b11010ba
  resourceVersion: "7404420"
  uid: 38d42ee2-dcee-420e-9260-2f3f5390f28a
spec:
  containers:
  - image: nginx:1.19
    imagePullPolicy: IfNotPresent
    name: nginx
    ports:
    - containerPort: 80
      protocol: TCP
    resources: {}
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-flm4s
      readOnly: true
  - env:
    - name: HTTP_PORT
      value: "8080"
    - name: HTTPS_PORT
      value: "11443"
    image: wbitt/network-multitool
    imagePullPolicy: Always
    name: network-multitool
    ports:
    - containerPort: 8080
      name: http-port
      protocol: TCP
    - containerPort: 11443
      name: https-port
      protocol: TCP
    resources:
      limits:
        cpu: 10m
        memory: 20Mi
      requests:
        cpu: 1m
        memory: 20Mi
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-flm4s
      readOnly: true
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  nodeName: ubuntu-hw
  preemptionPolicy: PreemptLowerPriority
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: kube-api-access-flm4s
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-02-15T09:36:29Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-02-15T09:36:43Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-02-15T09:36:43Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-02-15T09:36:29Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: containerd://78a48d998581ce5401ff8121c1e42ce6f27ebd984bcae3e79c2f5c50cad77ebf
    image: docker.io/wbitt/network-multitool:latest
    imageID: docker.io/wbitt/network-multitool@sha256:d1137e87af76ee15cd0b3d4c7e2fcd111ffbd510ccd0af076fc98dddfc50a735
    lastState: {}
    name: network-multitool
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2024-02-15T09:36:43Z"
  - containerID: containerd://c755476a9fced61a5a6e7e9b97800af9c5300e914e11803f7c300545f352408b
    image: docker.io/library/nginx:1.19
    imageID: docker.io/library/nginx@sha256:df13abe416e37eb3db4722840dd479b00ba193ac6606e7902331dcea50f4f1f2
    lastState: {}
    name: nginx
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2024-02-15T09:36:40Z"
  hostIP: 192.168.10.7
  phase: Running
  podIP: 10.1.169.85
  podIPs:
  - ip: 10.1.169.85
  qosClass: Burstable
  startTime: "2024-02-15T09:36:29Z"



~~~



2. Обновить версию nginx в приложении до версии 1.20, сократив время обновления до минимума. Приложение должно быть доступно.


Изменил nginx 1.19 на 1.20 

Добавил  параметры стратегии обновления, для того чтобы приложение было всегда доступно

~~~
strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1

~~~

Проверямем , что пооизошло обновление до 1.20


~~~
admin@ubuntu-hw:~/k8supdsoft$ kubectl describe deploy netology-deployment
Name:                   netology-deployment
Namespace:              default
CreationTimestamp:      Thu, 15 Feb 2024 09:36:28 +0000
Labels:                 app=main
Annotations:            deployment.kubernetes.io/revision: 2
Selector:               app=main
Replicas:               5 desired | 5 updated | 5 total | 5 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  1 max unavailable, 1 max surge
Pod Template:
  Labels:  app=main
  Containers:
   nginx:
    Image:        nginx:1.20
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:       <none>
   network-multitool:
    Image:       wbitt/network-multitool
    Ports:       8080/TCP, 11443/TCP
    Host Ports:  0/TCP, 0/TCP
    Limits:
      cpu:     10m
      memory:  20Mi
    Requests:
      cpu:     1m
      memory:  20Mi
    Environment:
      HTTP_PORT:   8080
      HTTPS_PORT:  11443
    Mounts:        <none>
  Volumes:         <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  netology-deployment-666dcf88d (0/0 replicas created)
NewReplicaSet:   netology-deployment-566fcf8d84 (5/5 replicas created)
Events:          <none>

~~~


3. Попытаться обновить nginx до версии 1.28, приложение должно оставаться доступным.

Заменил в деплое 1.20 на 1.28.

~~~

admin@ubuntu-hw:~/k8supdsoft$ kubectl get po
NAME                                   READY   STATUS             RESTARTS   AGE
netology-deployment-566fcf8d84-6n9pp   2/2     Running            0          9m40s
netology-deployment-566fcf8d84-9wgvm   2/2     Running            0          9m19s
netology-deployment-566fcf8d84-pwwb4   2/2     Running            0          9m18s
netology-deployment-566fcf8d84-prqnl   2/2     Running            0          9m1s
netology-deployment-768978d8d4-jlf5f   1/2     ImagePullBackOff   0          16s
netology-deployment-768978d8d4-4bvkj   1/2     ImagePullBackOff   0          17s


~~~

4. Откатиться после неудачного обновления.

Откатываемся

~~~
kubectl rollout status deployment netology-deployment
Waiting for deployment "netology-deployment" rollout to finish: 2 out of 5 new replicas have been updated...

Waiting for deployment spec update to be observed...
Waiting for deployment spec update to be observed...
Waiting for deployment "netology-deployment" rollout to finish: 4 out of 5 new replicas have been updated...
Waiting for deployment "netology-deployment" rollout to finish: 4 out of 5 new replicas have been updated...
Waiting for deployment "netology-deployment" rollout to finish: 4 out of 5 new replicas have been updated...
Waiting for deployment "netology-deployment" rollout to finish: 4 of 5 updated replicas are available...
deployment "netology-deployment" successfully rolled out

~~~

~~~
admin@ubuntu-hw:~/k8supdsoft$ kubectl rollout undo deployment netology-deployment
deployment.apps/netology-deployment rolled back
admin@ubuntu-hw:~/k8supdsoft$ kubectl get po
NAME                                   READY   STATUS    RESTARTS   AGE
netology-deployment-566fcf8d84-6n9pp   2/2     Running   0          27m
netology-deployment-566fcf8d84-9wgvm   2/2     Running   0          27m
netology-deployment-566fcf8d84-pwwb4   2/2     Running   0          27m
netology-deployment-566fcf8d84-prqnl   2/2     Running   0          27m
netology-deployment-566fcf8d84-p4xzt   2/2     Running   0          5s
admin@ubuntu-hw:~/k8supdsoft$ kubectl get po
NAME                                   READY   STATUS    RESTARTS   AGE
netology-deployment-566fcf8d84-6n9pp   2/2     Running   0          28m
netology-deployment-566fcf8d84-9wgvm   2/2     Running   0          27m
netology-deployment-566fcf8d84-pwwb4   2/2     Running   0          27m
netology-deployment-566fcf8d84-prqnl   2/2     Running   0          27m
netology-deployment-566fcf8d84-p4xzt   2/2     Running   0          13s

~~~






## Дополнительные задания — со звёздочкой*

Задания дополнительные, необязательные к выполнению, они не повлияют на получение зачёта по домашнему заданию. **Но мы настоятельно рекомендуем вам выполнять все задания со звёздочкой.** Это поможет лучше разобраться в материале.   

### Задание 3*. Создать Canary deployment

1. Создать два deployment'а приложения nginx.
2. При помощи разных ConfigMap сделать две версии приложения — веб-страницы.
3. С помощью ingress создать канареечный деплоймент, чтобы можно было часть трафика перебросить на разные версии приложения.

### Правила приёма работы

1. Домашняя работа оформляется в своем Git-репозитории в файле README.md. Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
2. Файл README.md должен содержать скриншоты вывода необходимых команд, а также скриншоты результатов.
3. Репозиторий должен содержать тексты манифестов или ссылки на них в файле README.md.
